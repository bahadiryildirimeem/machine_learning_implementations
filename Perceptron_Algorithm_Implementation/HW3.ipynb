{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bahadir_YILDIRIM_HW3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ilz5JwCiH-Ap"
      },
      "source": [
        "import numpy as np\n",
        "import skimage\n",
        "from skimage.feature import daisy\n",
        "from skimage import data\n",
        "from skimage.transform import resize\n",
        "from skimage.transform import rescale\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from skimage import io\n",
        "from natsort import natsorted, ns\n",
        "import scipy as sp\n",
        "import heapq\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0wVGnS7IDS1"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "fileName = \"HW3.zip\"\n",
        "\n",
        "with ZipFile(fileName, 'r') as zip:\n",
        "  zip.extractall()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH2ETwzmIHl1"
      },
      "source": [
        "# Listing images\n",
        "cannonList = os.listdir('/content/CaltechTinySplit/train/cannon')\n",
        "cellphoneList = os.listdir('/content/CaltechTinySplit/train/cellphone')\n",
        "\n",
        "cannonList = natsorted(cannonList)\n",
        "cellphoneList = natsorted(cellphoneList)\n",
        "\n",
        "nofClasses = 2\n",
        "# class0 is cannon, class1 is cellphone\n",
        "classNames = [0, 1]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIfof-HtZfHb"
      },
      "source": [
        "# Reading images\n",
        "cannonImList = []\n",
        "cellphoneImList = []\n",
        "\n",
        "# Classes\n",
        "cannonClassList = []\n",
        "cellphoneClassList = []\n",
        "\n",
        "# Cannon images\n",
        "for i in cannonList:\n",
        "  directory = '/content/CaltechTinySplit/train/cannon/' + i\n",
        "  if i != '.ipynb_checkpoints' and i != 'Thumbs.db':\n",
        "    tempIm = io.imread(directory, as_gray = False)\n",
        "    tempIm = resize(tempIm, (64, 64))\n",
        "    tempIm = tempIm.ravel()\n",
        "    cannonImList.append(tempIm)\n",
        "    cannonClassList.append(0)\n",
        "\n",
        "# Cellphone images\n",
        "for i in cellphoneList:\n",
        "  directory = '/content/CaltechTinySplit/train/cellphone/' + i\n",
        "  if i != '.ipynb_checkpoints' and i != 'Thumbs.db':\n",
        "    tempIm = io.imread(directory, as_gray = False)\n",
        "    tempIm = resize(tempIm, (64, 64))\n",
        "    tempIm = tempIm.ravel()\n",
        "    cellphoneImList.append(tempIm)\n",
        "    cellphoneClassList.append(1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozvJ4MTKCBYj"
      },
      "source": [
        "\n",
        "def tanhActivationFunc(x):\n",
        "  return ((np.exp(x) - np.exp(-1*x)) / (np.exp(x) + np.exp(-1*x)))\n",
        "def derivativeTanhActFunc(x):\n",
        "  val = tanhActivationFunc(x)\n",
        "  return (1 - pow(val, 2))\n",
        "def calculateDeltaWeight(rho, t, y, dervActVal, x):\n",
        "  return rho*(t - y)*dervActVal*x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-p_xBzJqyEO"
      },
      "source": [
        "def standardize(value):\n",
        "    mean = np.mean(value, axis=0)\n",
        "    std = np.std(value, axis=0)+0.000001\n",
        "    X_train = (value - mean) / std\n",
        "    return X_train"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_i3uQhSDprx"
      },
      "source": [
        "# Concatenating lists\n",
        "dataSetList = [*cannonImList, *cellphoneImList]\n",
        "dataClassList = [*cannonClassList, *cellphoneClassList]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgJCr3zZKA0-"
      },
      "source": [
        "# Perceptron Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGEo71rCGR5p"
      },
      "source": [
        "def trainPerceptron(inputs, t, weights, rho, iterNo):\n",
        "  appendedDataSetList = inputs\n",
        "  dataClassList = t\n",
        "  for i in range(iterNo):\n",
        "    sumVector = np.zeros(len(appendedDataSetList))\n",
        "    # Feed forward\n",
        "    for j in range(len(appendedDataSetList)):\n",
        "      if(appendedDataSetList[j].shape[0] == weights.shape[0]):\n",
        "        arr = np.dot(weights, appendedDataSetList[j])\n",
        "        sumVector[j] = arr\n",
        "    stdVal = standardize(sumVector)\n",
        "    for j in range(len(appendedDataSetList)):\n",
        "      if(appendedDataSetList[j].shape[0] == weights.shape[0]):\n",
        "        y = tanhActivationFunc(stdVal[j])\n",
        "        target = dataClassList[j]\n",
        "        # Feed backward\n",
        "        deltaWeight = calculateDeltaWeight(rho, target, y, derivativeTanhActFunc(y), appendedDataSetList[j])\n",
        "        weights += deltaWeight;\n",
        "  return weights\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBTn4vrpoU7x"
      },
      "source": [
        "appendedDataSetList = []\n",
        "appendingVal = 0\n",
        "for i in range(len(dataSetList)):\n",
        "  x = dataSetList[i]\n",
        "  x = np.append(x, [appendingVal])\n",
        "  appendedDataSetList.append(x)\n",
        "appendedDataSetList, dataClassList = shuffle(appendedDataSetList, dataClassList) # don't you forget the parameters that enters\n",
        "                                                                                 # the shuffle function must be function parameter as inputs and t"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLu3YlWuHH59"
      },
      "source": [
        "weights = np.random.random((len(appendedDataSetList[0])))\n",
        "weights = trainPerceptron(appendedDataSetList, dataClassList, weights, 0.001, 1000)\n",
        "np.save('weights.npy', weights) # save"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQSc-XS93HYx"
      },
      "source": [
        "# Testing Phase "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzYO21eN2v5Y"
      },
      "source": [
        "weights = np.load('weights.npy') # load"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE2ldJKsJ3xD"
      },
      "source": [
        "# Perceptron Testing Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIPrujIgJw2z"
      },
      "source": [
        "def testPerceptron(sample_test, weights):\n",
        "  sumVector = np.zeros(len(sample_test))\n",
        "  for i in range(len(sample_test)):\n",
        "    sum = np.dot(sample_test[i], weights)\n",
        "    sumVector[i] = sum\n",
        "  sumVector = standardize(sumVector)\n",
        "  y = tanhActivationFunc(sumVector)\n",
        "  return y"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1OuQxej3BSK"
      },
      "source": [
        "# Listing images\n",
        "cannonTestList = os.listdir('/content/CaltechTinySplit/test/cannon')\n",
        "cellphoneTestList = os.listdir('/content/CaltechTinySplit/test/cellphone')\n",
        "\n",
        "cannonTestList = natsorted(cannonTestList)\n",
        "cellphoneTestList = natsorted(cellphoneTestList)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uZ_Erul3uaV"
      },
      "source": [
        "# Reading Test images\n",
        "cannonTestImList = []\n",
        "cellphoneTestImList = []\n",
        "\n",
        "# Classes\n",
        "cannonTestClassList = []\n",
        "cellphoneTestClassList = []\n",
        "\n",
        "# Accordion test images\n",
        "for i in cannonTestList:\n",
        "  directory = '/content/CaltechTinySplit/test/cannon/' + i\n",
        "  if i != '.ipynb_checkpoints' and i != 'Thumbs.db':\n",
        "    tempIm = io.imread(directory, as_gray = False)\n",
        "    tempIm = resize(tempIm, (64, 64))\n",
        "    tempIm = tempIm.ravel()\n",
        "    cannonTestImList.append(tempIm)\n",
        "    cannonTestClassList.append(0)\n",
        "\n",
        "# Airplane test images\n",
        "for i in cellphoneTestList:\n",
        "  directory = '/content/CaltechTinySplit/test/cellphone/' + i\n",
        "  if i != '.ipynb_checkpoints' and i != 'Thumbs.db':\n",
        "    tempIm = io.imread(directory, as_gray = False)\n",
        "    tempIm = resize(tempIm, (64, 64))\n",
        "    tempIm = tempIm.ravel()\n",
        "    cellphoneTestImList.append(tempIm)\n",
        "    cellphoneTestClassList.append(1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7GabGlF5r8F"
      },
      "source": [
        "appendedCannonTestList = []\n",
        "for i in range(len(cannonTestImList)):\n",
        "  x = cannonTestImList[i]\n",
        "  x = np.append(x, [1]) # bias value\n",
        "  appendedCannonTestList.append(x)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML_R8Wp0iE5V"
      },
      "source": [
        "appendedCellphoneTestList = []\n",
        "for i in range(len(cellphoneTestList)):\n",
        "  x = cellphoneTestImList[i]\n",
        "  x = np.append(x, [1]) # bias value\n",
        "  appendedCellphoneTestList.append(x)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1t83c-A24dLP",
        "outputId": "479decf8-0a5a-46cf-ec31-129bfa31c1c9"
      },
      "source": [
        "# Testing canon list\n",
        "cannonTestOutputs = testPerceptron(appendedCannonTestList, weights)\n",
        "print(cannonTestOutputs)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.14932068 -0.47304869  0.94423864 -0.84604322  0.12998825]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JxR2juE3iXNA",
        "outputId": "87292f5f-e8f2-4915-9d6d-47644ac1814a"
      },
      "source": [
        "# Testing cellphone list\n",
        "cellphoneTestOutputs = testPerceptron(appendedCellphoneTestList, weights)\n",
        "print(cellphoneTestOutputs)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.96202855  0.20952595  0.3068603   0.23605937  0.64495183  0.85436299\n",
            " -0.68400091]\n"
          ]
        }
      ]
    }
  ]
}